\chapter{Experimenty}
\label{chap:experiments}

V~tejto kapitole porovnáme jednotlivé typy architektúr neurónových sietí, porovnáme ich úspešnosť a ukážeme, ktorá z~nich je najvhodnejšia. Ďalej sa budeme venovať aj predspracovaniu segmentov, ktoré priamo ovplyvňuje vlastnosti trénovania a úspešnosť sietí.
\bigskip

\section{Trénovanie}

%TODO treba citaciu?
Trénovanie dopredných sietí sme robili pomocou algoritmu \textit{backpropagation} - algoritmu spätného šírenia chyby \cite{haykin1999neural}. Sieti sme postupne predkladali dáta s~informáciou či sa jedná o~ruku alebo nie. Pred každou epochou sme dáta náhodne preusporiadali. 

Pri rekurentných sieťach sme predkladali postupnosti dát, pričom sme zachovávali poradie obrázkov v~postupnosti. Rekurentné vstupy sme updatli len v~prípade, že sme rozpoznali ruku. Po každej postupnosti sme rekurentné vstupy resetli na 0. Takto simulujeme správanie siete v~reálnej aplikácii.

\section{Testovanie a vyhodnocovanie neurónových sietí}
Pri trénovaní sa snažíme minimalizovať kvadratickú chybu. Preto aj pri vyhodnocovaní úspešnosti sietí budeme používať túto metriku.

Kvadratická chyba sa počíta takto: $$\frac{1}{2}(t-o)^2$$
$t$ je cieľová hodnota a $o$ je výstup siete. V~tabuľkách budeme uvádzať priemernú kvadratickú chybu, ktorú budeme počítať ako súčet všetkých kvadratických chýb deleno počet testovacích vstupov. 

\section{Trénovacie a testovacie dáta}
\label{chap:data}

Na generovanie dát sme použili upravenú verziu našej aplikácie (kapitola \ref{chap:saveimageapp}), ktorá umožňovala ukladanie vysegmentovaných obrázkov na disk bez toho, aby došlo k~výraznému spomaleniu. 

Trénovacie dáta sme rozdelili na dve sady. Každá sada bola rozdelená na dve disjunktné množiny -- trénovaciu a testovaciu. 

Prvou sadou sme vyhodnocovali vlastnosti rôznych typov architektúr neurónových sietí a vplyv fourierovej transformácie. Obsahovala dáta, ktoré boli rozdelené do postupností. To nám umožňovalo trénovať nimi rekurentné neurónové siete. Dopredné siete tieto dáta brali ako jednotlivé obrázky. Na jednu postupnosť pripadá v~priemere približne 11 obrázkov. Sada obsahuje rozdielové obrázky\footnote{kapitola \ref{chap:diffimg}} a k~nim zodpovedajúce fourierove transformácie.

Druhá sada bola špecializovaná na vyhodnocovanie použitia pôvodného vs. rozdielového obrázka. Z~tejto sady boli vyňaté obrázky rúk, ktoré sa nepodarilo algoritmu floodfill správne vyselektovať. Porovnávali sme teda úspešnosti v~ideálnych prípadoch. Sada obsahuje rozdielové obrázky, k~nim zodpovedajúce pôvodné obrázky a fourierove transformácie zodpovedajúce obom typom.

\begin{table}[h]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Sada} & \textbf{ruky} & \textbf{ostatné} & \textbf{ruky} & \textbf{ostatné} \\ \hline
1. sada & 168 & 478 & 245  & 568 \\ \hline
2. sada & 96 & 174 & 149 & 165 \\ 
\hline
\end{tabular}
\caption{Veľkosti sád vstupov}
\label{tab:neuroncountcmp}
\end{table}

Keďže obrázkov rúk je v~dátach menej ako ostatných a sieť, ktorá by na všetko povedala že to ruka nie je by mala úspešnosť $>60\%$, percentuálnu úspešnosť počítame ako \textbf{priemer percentuálnej úspešnosti} na rukách a na ostatných obrázkoch.

\section{Porovnanie architektúr neurónových sietí}

\subsection{Typ 1: Viac vrstvová dopredná neurónová sieť}

Experimentálne sme zistili, že dvojvrstvová sieť na tento problém stačí a tretia vrstva nepomáha -- nedarilo sa nám ju natrénovať. V~tabuľke \ref{tab:neuroncountcmp} uvádzame úspešnosti pre 2-vrstvovú sieť na dátach fourierovych transformácií.

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Počet neurónov} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba} \\ \hline
30 & 64,3 & 0,1036 & 99,8 & 0,001 \\ \hline
40 & 63,22 & 0,0956 & 99,8 & 0,001 \\ \hline
45 & 64,19 & 0,098 & 99,8 & 0,001 \\ \hline
47 & 65,07 & 0,099 & 100 & 0,0004 \\ \hline
55 & 63,46 & 0,099 & 100 & 0,0004 \\ \hline
60 & 63,48 & 0,099 & 100 & 0,0003 \\ 
\hline
\end{tabular}
\caption{Porovnanie úspešnosti doprednej NS pri rôznych počtoch neurónov}
\label{tab:neuroncountcmp}
\end{table}

Môžeme si všimnúť, že pridávanie neurónov donekonečna nemusí pomôcť a zbytočne veľa neurónov môže aj uškodiť.

\subsection{Typ 2: Upravená verzia viac vrstvovej doprednej neurónovej siete}

Pri tomto type siete sa nám podarilo natrénovať 2 aj 3-vrstvové architektúry, v~tabuľke \ref{tab:neuroncountcmp2} sa budú teda vyskytovať obe. Vrstvy sú oddelené ,,;'' a sú písané od najvrchnejšej po najspodnejšiu. Pri spodnej vrstve je v~zátvorke počet neurónov na jednu časť obrázka.

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Počet neurónov} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba} \\ \hline
48(3)& 66,39 & 0,0872 & 99,39 & 0,0131 \\ \hline
112(7)& 66,56 & 0,1015 & 99,65 & 0,004 \\ \hline 
176(11)& 67,47 & 0,0957 & 99,39 & 0,0112 \\ \hline
240(15)& 64,89 & 0,1207 & 99,83 & 0,0016 \\ \hline
320(20)& 64,12 & 0,1108 & 99,91 & 0,0007 \\ \hline
7; 48(3)& 66,32 & 0,0947 & 99,53 & 0,0038 \\ \hline 
7; 112(7)& 67,05 & 0,1042 & 99,21 & 0,0053 \\ \hline 
7; 176(11)& 67,37 & 0,1038 & 99,56 & 0,0023 \\ \hline
7; 208(13)& 65,8  & 0,1035 & 99,36 & 0,0052 \\ \hline 
7; 272(17)& 66,14 & 0,1032 & 98,95 & 0,0078 \\ \hline 
7; 320(20)& 65,84& 0,1156 & 99,91 & 0,0009\\ \hline 
11; 112(7)& 64,1 & 0,1108 & 99,91 & 0,0004 \\ \hline
12; 144(9)& 66,27 & 0, 0978 & 99,74 & 0,003 \\ \hline
12; 480(30)& 67.24 & 0,0983 & 99,53 & 0,0023 \\ \hline 
13; 208(13)& 63,86 & 0,1001 & 99,33 & 0,0036 \\ \hline 
17; 112(7)& 62,52 & 0,1043 & 100 & 0,0023 \\ \hline
\end{tabular}
\caption{Porovnanie úspešnosti upravenej NS pri rôznych počtoch neurónov}
\label{tab:neuroncountcmp2}
\end{table}

Všimnime si že tretia vrstva nám v~úspešnosti veľmi nepomohla, hoci skrátila dobu trénovania - stačila asi 1/4 epoch oproti 2 vrstvám. Keďže ale v~praxi je pridanie ďalšej vrstvy spomalením, tak dve vrstvy budú v~tomto prípade lepšie.

Oproti sieťam typu 1, vidíme určitý nárast úspešností približne o~2\%, pričom sieť obsahuje menej váh, čiže sa rýchlejšie trénuje aj rýchlejšie počíta.

\subsection{Typ 3: Rekurentná neurónová sieť}
Pri tomto type sietí sme mali viacero možností ako zvoliť rekurentné neuróny. Mohli sme ich nechať len na spodnej vrstve, alebo sme ich mohli dať do celej neurónovej siete.

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}} \\ 
\hline
\textbf{Rekurentná vrstva} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba}  \\ \hline
spodná(11) &  67,88 & 0,1106 & 98,8 & 0,005  \\ \hline
spodná(20) & 67,01 & 0,109 & 99,47 & 0,0029  \\ \hline
všetky(11) & 61,84 & 0,1055 & 99,82 & 0,0026  \\ \hline
všetky(20) & 65,07 & 0,1116 & 99,47 & 0,0033  \\ \hline
\end{tabular}
\caption{Porovnanie úspešnosti rekurentnej NS pri rôznom umiestnení rekurencie}
\label{tab:reclayercmp}
\end{table}

V~tabuľke \ref{tab:reclayercmp} vidíme, že lepšie si počína sieť s~rekurenciou len na spodnej vrstve. Obe siete sú 2-vrstvové, v~zátvorke je počet neurónov na jednu časť dát -- tak ako v~predošlej kapitole. Informácie z~vyšších vrstiev sú pre sieť mätúce. V~ďalších testoch (tabuľka \ref{tab:neuroncountcmp3}) teda budeme vychádzať z~architektúry, ktorá má rekurentné neuróny len na spodnej vrstve. Vyskúšame 2 aj 3-vrstvové architektúry.

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Počet neurónov} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba} \\ \hline
112(7) & 65,63 & 0,1049 & 98,54 & 0,0056  \\ \hline
%144(9) & 64,37 & 0,0984 & 98,8 & 0,0116  \\ \hline
176(11) & 67,88 & 0,1106 & 98,8 & 0,005  \\ \hline
%208(13) & 65,68 & 0,0961 & 98,34 & 0,0154  \\ \hline
240(15) & 65,16 & 0,1173 & 99,53 & 0,0028  \\ \hline
320(20) & 67,01 & 0,109 & 99,47 & 0,0029 \\ \hline
7; 176(11) & 66,13 & 0,1107 & 99,74 & 0,0018 \\ \hline
12; 144(9) & 65,73 & 0,0937 & 98,87 & 0,0083 \\ \hline
\end{tabular}
\caption{Porovnanie úspešnosti rekurentnej NS pri rôznych počtoch neurónov}
\label{tab:neuroncountcmp3}
\end{table}

Ani v~tomto prípade nám nepomohla ďalšia vrstva. Pri 2-vrstvových architektúrach rekurencia mierne pomohla.

\subsection{Zhrnutie}

%TODO časy a trenovanie?
Vylepšeniami architektúry sa nám podarilo zdvihnúť úspešnosť o~\textbf{2,81\%} a nájsť architektúru s~úspešnosťou \textbf{67,88\%}. Ukázalo sa, že je lepšie použiť 2-vrstvovú sieť ako 3-vrstvovú. Ďalej sme zistili, že keď budú mať neuróny prístup len k~časti obrázka, môžeme ich použiť viac a dosiahnuť lepšiu úspešnosť. Nakoniec sa nám podarilo ukázať, že pridaním rekurentných spojení na spodnú vrstvu dokážeme ešte trochu zvýšiť úspešnosť.

Úspešnosť na rukách sa pohybovala okolo 40-50\% a na ostatných obrázkoch 80-90\%. Sieť teda dokáže dobre odfiltrovať zlé obrázky, pričom má pomerne dobrú úspešnosť aj na rukách.

\section{Porovnanie úspešnosti pri rôznom spôsobe predspracovania}

\subsection{Vplyv Fourierovej transformácie}

Pre porovnanie fourierovej transformácie a rozdielových obrázkov sme použili 3-vrstvovú upravenú neurónovú sieť. Vybrali sme ju pre to, že 2-vrstvovú sa nám nepodarilo natrénovať. Ani pri tejto architektúre sa nám však nedarili sieť natrénovať na úspešnosť viac ako 71\%. Už z~toho je vidieť výhoda fourierovej transformácie. Počty neurónov sme vybrali tie, ktoré dopadli v~predošlom teste najlepšie (tabuľka \ref{tab:neuroncountcmp2}) -- [7; 112(7)] a [7; 176(11)].

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Typ dát} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba}\\ \hline
\textbf{Obrázok(7)} & 65,16\% & 0,1052 & 70,71 & 0.0864 \\ \hline
\textbf{Fourierova tr.(7)} & 67,05 & 0,1042 & 99,21 & 0,0053 \\ \hline 
\textbf{Obrázok(11)} & 65,06\% & 0,096 & 70,76 & 0.0887 \\ \hline
\textbf{Fourierova tr.(11)} & 67,37 & 0,1038 & 99,56 & 0,0023 \\ \hline
\end{tabular}
\caption{Porovnanie úspešnosti NS na dátach Fourierovej tr. a rozdielového obrázku}
\label{tab:neuraldataftcmp}
\end{table}

Z~tabuľky \ref{tab:neuraldataftcmp} je vidieť zlepšenie o~2\% pri použití Fourierovej transformácie. Okrem toho nám
Fourierova transformácia dáva potenciál zdvihnúť úspešnosť pri väčšom množstve trénovacích dát a širšie možnosti trénovania. 

\subsection{Rozdielový vs. pôvodný obraz}

Pri tomto teste sme použili na trénovanie a testovanie \textit{sadu 2} (kapitola \ref{chap:data}) v~ktorej boli trénovacie a testovacie dáta podobnejšie, preto je aj úspešnosť vyššia. Využili sme 3-vrstvovú architektúru upravenej doprednej neurónovej siete s~počtami neurónov [7; 176(11)], z~podobných dôvodov ako v~predošlej kapitole.

\begin{table}[h]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Typ dát} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba}\\ \hline
\textbf{Rozdielový obr.} & 76,64 & 0,071 & 92,9 & 0,0303 \\ \hline
\textbf{Pôvodný obr.} & 66,51 & 0,123 & 77,46 & 0,0782 \\ \hline
\textbf{Rozdielový -- FT} & 81,78 & 0,0821 & 95,06 & 0,0128\\ \hline
\textbf{Pôvodný -- FT} & 74,73 & 0,1156 & 90,13 & 0,0279\\ \hline
\end{tabular}
\caption{Porovnanie úspešnosti NS na dátach rozdielového obrázku, pôvodného obrázku a ich Fourierovych transformácií}
\label{tab:neuraldatacmp}
\end{table}

Z~tabuľky \ref{tab:neuraldatacmp} je vidieť, že úspešnosť siete na dátach pôvodného obrázka je značne nižšia ako na rozdielovom obrázku a to aj pri použití fourierovej transformácie. Z~toho vyplýva že tento typ dát nie je vhodný.

\subsection{Zhrnutie}

Z~tabuliek vidíme, že Fourierova transformácia pomáha nie len pri trénovaní, ale aj pri celkovej úspešnosti neurónovej siete. Sieť je možné rýchlejšie a lepšie natrénovať a trénovať na väčších dátach.

Dáta získané na základe pôvodného obrázka sa ukázali ako nevhodné, sieť sa na nich veľmi ťažko učí a ani Fourierova transformácia na týchto dátach nedosahuje takú vysokú úspešnosť ako z~rozdielového obrázka. Preto sme sa rozhodli v~aplikácii tento prístup nepoužiť.
