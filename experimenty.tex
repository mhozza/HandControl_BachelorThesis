\chapter{Experimenty}
\label{chap:experiments}

V~tejto kapitole porovnáme jednotlivé typy architektúr neurónových sietí, porovnáme ich úspešnosť a ukážeme, ktorá z~nich je najvhodnejšia. Ďalej sa budeme venovať aj predspracovaniu segmentov, ktoré priamo ovplyvňuje vlastnosti trénovania a úspešnosť sietí.
\bigskip

\section{Trénovanie}

%TODO treba citaciu?
Trénovanie dopredných sietí sme robili pomocou algoritmu \textit{backpropagation} - algoritmu spätného šírenia chyby \cite{haykin1999neural}. Sieti sme postupne predkladali dáta s~informáciou či sa jedná o~ruku alebo nie. Pred každou epochou sme dáta náhodne preusporiadali. 

Pri rekurentných sieťach sme predkladali postupnosti dát, pričom sme zachovávali poradie obrázkov v~postupnosti. Rekurentné vstupy sme updatli len v~prípade, že sme rozpoznali ruku. Po každej postupnosti sme rekurentné vstupy resetli na 0. Takto simulujeme správanie siete v~reálnej aplikácii.

\section{Testovanie a vyhodnocovanie neurónových sietí}
Pri trénovaní sa snažíme minimalizovať kvadratickú chybu. Preto aj pri vyhodnocovaní úspešnosti sietí budeme používať túto metriku.

Kvadratická chyba sa počíta takto: $$\frac{1}{2}(t-o)^2$$
$t$ je cieľová hodnota a $o$ je výstup siete. V~tabuľkách budeme uvádzať priemernú kvadratickú chybu, ktorú budeme počítať ako súčet všetkých kvadratických chýb deleno počet testovacích vstupov. 

\section{Trénovacie a testovacie dáta}

Na generovanie dát sme použili upravenú verziu našej aplikácie (kapitola \ref{chap:saveimageapp}), ktorá umožňovala ukladanie vysegmentovaných obrázkov na disk bez toho, aby došlo k~výraznému spomaleniu. 

Trénovacie dáta sme rozdelili na dve sady. Každá sada bola rozdelená na dve disjunktné množiny -- trénovaciu a testovaciu. 

Prvou sadou sme vyhodnocovali vlastnosti rôznych typov architektúr neurónových sietí a vplyv fourierovej transformácie. Obsahovala dáta, ktoré boli rozdelené do postupností. To nám umožňovalo trénovať nimi rekurentné neurónové siete. Dopredné siete tieto dáta brali ako jednotlivé obrázky. Na jednu postupnosť pripadá v~priemere približne 11 obrázkov. Sada obsahuje rozdielové obrázky\footnote{kapitola \ref{chap:diffimg}} a k~nim zodpovedajúce fourierove transformácie.

Druhá sada bola špecializovaná na vyhodnocovanie použitia pôvodného vs. rozdielového obrázka. Z~tejto sady boli vyňaté obrázky rúk, ktoré sa nepodarilo algoritmu floodfill správne vyselektovať. Porovnávali sme teda úspešnosti v~ideálnych prípadoch. Sada obsahuje rozdielové obrázky, k~nim zodpovedajúce pôvodné obrázky a fourierove transformácie zodpovedajúce obom typom.

\begin{table}[h]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Sada} & \textbf{ruky} & \textbf{ostatné} & \textbf{ruky} & \textbf{ostatné} \\ \hline
1. sada & 168 & 478 & 245  & 568 \\ \hline
2. sada & & & & \\ 
\hline
\end{tabular}
\caption{Veľkosti sád vstupov}
\label{tab:neuroncountcmp}
\end{table}

\todo doplnit tabulku

Keďže obrázkov rúk je v dátach menej ako ostatných a sieť, ktorá by na všetko povedala že to ruka nie je by mala úspešnosť $>60\%$, percentuálnu úspešnosť počítame ako \textbf{priemer percentuálnej úspešnosti} na rukách a na ostatných obrázkoch.

\section{Porovnanie architektúr neurónových sietí}

\subsection{Typ 1: Viac vrstvová dopredná neurónová sieť}

Experimentálne sme zistili, že dvojvrstvová sieť na tento problém stačí a tretia vrstva nepomáha -- nedarilo sa nám ju natrénovať. V tabuľke \ref{tab:neuroncountcmp} uvádzame úspešnosti pre 2-vrstvovú sieť na dátach fourierovych transformácií.

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Počet neurónov} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba} \\ \hline
30 & 64,3 & 0,1036 & 99,8 & 0,001 \\ \hline
40 & 63,22 & 0,0956 & 99,8 & 0,001 \\ \hline
45 & 64,19 & 0,098 & 99,8 & 0,001 \\ \hline
47 & 65,07 & 0,099 & 100 & 0,0004 \\ \hline
55 & 63,46 & 0,099 & 100 & 0,0004 \\ \hline
60 & 63,48 & 0,099 & 100 & 0,0003 \\ 
\hline
\end{tabular}
\caption{Porovnanie úspešnosti doprednej NS pri rôznych počtoch neurónov}
\label{tab:neuroncountcmp}
\end{table}

Môžeme si všimnúť, že pridávanie neurónov donekonečna nemusí pomôcť a zbytočne veľa neurónov môže aj uškodiť.

\subsection{Typ 2: Upravená verzia viac vrstvovej doprednej neurónovej siete}

Pri tomto type siete sa nám podarilo natrénovať 2 aj 3-vrstvové architektúry, v tabuľke \ref{tab:neuroncountcmp2} sa budú teda vyskytovať obe. Vrstvy sú oddelené ,,;'' a sú písané od najvrchnejšej po najspodnejšiu. Pri spodnej vrstve je v zátvorke počet neurónov na jednu časť obrázka.

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Počet neurónov} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba} \\ \hline
48(3)& 66,39 & 0,0872 & 99,39 & 0,0131 \\ \hline
112(7)& 66,56 & 0,1015 & 99,65 & 0,004 \\ \hline 
176(11)& 67,47 & 0,0957 & 99,39 & 0,0112 \\ \hline
240(15)& 64,89 & 0,1207 & 99,83 & 0,0016 \\ \hline
320(20)& 64,12 & 0,1108 & 99,91 & 0,0007 \\ \hline
7; 48(3)& 66,32 & 0,0947 & 99,53 & 0,0038 \\ \hline 
7; 112(7)& 67,05 & 0,1042 & 99,21 & 0,0053 \\ \hline 
7; 176(11)& 67,37 & 0,1038 & 99,56 & 0,0023 \\ \hline
7; 208(13)& 65,8  & 0,1035 & 99,36 & 0,0052 \\ \hline 
7; 272(17)& 66,14 & 0,1032 & 98,95 & 0,0078 \\ \hline 
7; 320(20)& 65,84& 0,1156 & 99,91 & 0,0009\\ \hline 
11; 112(7)& 64,1 & 0,1108 & 99,91 & 0,0004 \\ \hline
12; 144(9)& 66,27 & 0, 0978 & 99,74 & 0,003 \\ \hline
12; 480(30)& 67.24 & 0,0983 & 99,53 & 0,0023 \\ \hline 
13; 208(13)& 63,86 & 0,1001 & 99,33 & 0,0036 \\ \hline 
17; 112(7)& 62,52 & 0,1043 & 100 & 0,0023 \\ \hline
\end{tabular}
\caption{Porovnanie úspešnosti upravenej NS pri rôznych počtoch neurónov}
\label{tab:neuroncountcmp2}
\end{table}

Všimnime si že tretia vrstva nám v úspešnosti veľmi nepomohla, hoci skrátila dobu trénovania - stačila asi 1/4 epoch oproti 2 vrstvám. Keďže ale v praxi je pridanie ďalšej vrstvy spomalením, tak dve vrstvy budú v tomto prípade lepšie.

Oproti sieťam typu 1, vidíme určitý nárast úspešností približne o 2\%, pričom sieť obsahuje menej váh, čiže sa rýchlejšie trénuje aj rýchlejšie počíta.

\subsection{Typ 3: Rekurentná neurónová sieť}
Pri tomto type sietí sme mali viacero možností ako zvoliť rekurentné neuróny. Mohli sme ich nechať len na spodnej vrstve, alebo sme ich mohli dať do celej neurónovej siete.

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}} \\ 
\hline
\textbf{Rekurentná vrstva} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba}  \\ \hline
spodná(11) &  67,88 & 0,1106 & 98,8 & 0,005  \\ \hline
spodná(20) & 67,01 & 0,109 & 99,47 & 0,0029  \\ \hline
všetky(11) & 61,84 & 0,1055 & 99,82 & 0,0026  \\ \hline
všetky(20) & 65,07 & 0,1116 & 99,47 & 0,0033  \\ \hline
\end{tabular}
\caption{Porovnanie úspešnosti rekurentnej NS pri rôznom umiestnení rekurencie}
\label{tab:reclayercmp}
\end{table}

V tabuľke \ref{tab:reclayercmp} vidíme, že lepšie si počína sieť s rekurenciou len na spodnej vrstve. Obe siete sú 2-vrstvové, v zátvorke je počet neurónov na jednu časť dát -- tak ako v predošlej kapitole. Informácie z vyšších vrstiev sú pre sieť mätúce. V ďalších testoch (tabuľka \ref{tab:neuroncountcmp3}) teda budeme vychádzať z architektúry, ktorá má rekurentné neuróny len na spodnej vrstve. Vyskúšame 2 aj 3-vrstvové architektúry.

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Počet neurónov} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba} \\ \hline
112(7) & 65,63 & 0,1049 & 98,54 & 0,0056  \\ \hline
%144(9) & 64,37 & 0,0984 & 98,8 & 0,0116  \\ \hline
176(11) & 67,88 & 0,1106 & 98,8 & 0,005  \\ \hline
%208(13) & 65,68 & 0,0961 & 98,34 & 0,0154  \\ \hline
240(15) & 65,16 & 0,1173 & 99,53 & 0,0028  \\ \hline
320(20) & 67,01 & 0,109 & 99,47 & 0,0029 \\ \hline
7; 176(11) & 66,13 & 0,1107 & 99,74 & 0,0018 \\ \hline
12; 144(9) & 65,73 & 0,0937 & 98,87 & 0,0083 \\ \hline
\end{tabular}
\caption{Porovnanie úspešnosti rekurentnej NS pri rôznych počtoch neurónov}
\label{tab:neuroncountcmp3}
\end{table}

Ani v tomto prípade nám nepomohla ďalšia vrstva. Pri 2-vrstvových architektúrach rekurencia mierne pomohla.

\subsection{Zhrnutie}

%TODO časy a trenovanie?
Vylepšeniami architektúry sa nám podarilo zdvihnúť úspešnosť o \textbf{2,81\%} a nájsť architektúru s úspešnosťou \textbf{67,88\%}. Ukázalo sa, že je lepšie použiť 2-vrstvovú sieť ako 3-vrstvovú. Ďalej sme zistili, že keď budú mať neuróny prístup len k časti obrázka, môžeme ich použiť viac a dosiahnuť lepšiu úspešnosť. Nakoniec sa nám podarilo ukázať, že pridaním rekurentných spojení na spodnú vrstvu dokážeme ešte trochu zvýšiť úspešnosť.

Úspešnosť na rukách sa pohybovala okolo 40-50\% a na ostatných obrázkoch 80-90\%. Sieť teda dokáže dobre odfiltrovať zlé obrázky, pričom má pomerne dobrú úspešnosť aj na rukách.

\section{Porovnanie rôznych typov dát}

\subsection{Fourierova transformácia}

Pre porovnanie fourierovej transformácie a rozdielových obrázkov sme použili 3-vrstvovú upravenú neurónovú sieť. Vybrali sme ju pre to, že 2-vrstvovú sa nám nepodarilo natrénovať. Ani pri tejto architektúre sa nám však nedarili sieť natrénovať na úspešnosť viac ako 71\%. Už z toho je vidieť výhoda fourierovej transformácie. Počty neurónov sme vybrali tie, ktoré dopadli v predošlom teste najlepšie (tabuľka \ref{tab:neuroncountcmp2}) -- [7; 112(7)] a [7; 176(11)].

\begin{table}[htp]
\catcode`\-=12 %kvoli babelu a pomlcke
\centering
\begin{tabular}{|l|c|c|c|c|}
\cline{2-5}
\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}}\\ 
\hline
\textbf{Typ dát} & \textbf{úspešnosť}(\%) & \textbf{chyba} & \textbf{úspešnosť}(\%) & \textbf{chyba}\\ \hline
\textbf{Obrázok(7)} & 65,16\% & 0,1052 & 70,71 & 0.0864 \\ \hline
\textbf{Fourierova tr.(7)} & 67,05 & 0,1042 & 99,21 & 0,0053 \\ \hline 
\textbf{Obrázok(11)} & 65,06\% & 0,096 & 70,76 & 0.0887 \\ \hline
\textbf{Fourierova tr.(11)} & 67,37 & 0,1038 & 99,56 & 0,0023 \\ \hline
\end{tabular}
\caption{Porovnanie úspešnosti NS pri rôznych dátach}
\label{tab:neuraldataftcmp}
\end{table}

Z tabuľky \ref{tab:neuraldataftcmp} je vidieť zlepšenie o 2\% pri použití Fourierovej transformácie. Okrem toho nám
Fourierova transformácia dáva potenciál zdvihnúť úspešnosť pri väčšom množstve trénovacích dát a širšie možnosti trénovania. 

\subsection{Rozdielový vs. pôvodný obraz}

\todo 

\subsection{Zhrnutie}

\todo 
%Nevýhodou rozdielového obrázka je, že zmena spôsobená pohybom sa v ňom vyskytne dvakrát. Raz na mieste, kam sa objekt posunul a raz na mieste odkiaľ sa posunul. Toto sme chceli eliminovať tak, že sa vyberie ruka z pôvodného obrázka podľa farby. Táto ruka tam bude vždy len raz. Bohužiaľ tento prístup mal viac zlých vlastností ako dobrých.

%Pri vyberaní obrázka treba mať nastavené správne parametre, podľa ktorých sa rozhoduje čo pridať do výberu a čo nie. Tieto parametre veľmi závisia od osvetlenia. Navyše osvetlenie sa môže meniť pri pohybe ruky, čo veľmi stažuje nastavenie správnych parametrov. Pred použitím aplikácie by sa aplikácia musela nakalibrovať, čo znižuje komfort jej použitia.

%Ďalší problém je správne tipnúť bod, ktorý patrí ruke, aby sa z neho mohla odštartovať selekcia. Pokiaľ by bola v danom obdĺžniku len dlaň, tak nie je až také ťažké sa správne trafiť - je takmer isté, že kúsok pod stredom obrázka bude dlaň. Bohužiaľ často sa stane, že užívaťeľ pohne nielen rukou, ale aj predlaktím a segmentačný algoritmus zaradí do segmentu aj predlaktie. Potom sa môže stať, že bod ruky netrafíme.

%{\color{red}
%Rozhodujúcim problémom však bolo to, že úspešnosť siete na dátach, ktoré ani neobsahovali zle vybraté ruky bola aj tak nižšia ako u rozdielového obrázka (tabuľka \ref{tab:neuraldatacmp}). Preto sme sa rozhodli radšej pridať ďalšie dáta do trénovacej množiny pre rozdielové obrázky. Pri vyhodnocovaní tejto časti sme použili menšiu trénovaciu a testovaciu sadu, ktorá obsahovala cca 350 trénovacích a 300 testovacích vzorov. Sada neobsahovala zle vybraté ruky.
%}

%\subsection{Fourierova transformácia} \label{sect:ft}
%Fourierova transformácia zvykne často pomáhať, keď sa použie na predspracovanie dát pri trénovaní obrazových alebo zvukových vzoriek. Preto sme sa aj my rozhodli vyskúšať aký bude mať vplyv na úspešnosť.

%Fourierova transformácia bola použitá na segment ako celok, potom bola prevedená do reálnych čísel ako absolútna hodnota z komplexného čísla a následne normalizovaná.

%Konvergencia chyby pri trénovaní bola značne rýchlejšia a použitie transformácie umožnilo dosiahnuť menšiu chybu na trénovacej množine. 

%TODO
%Úspešnosť na testovacej množine bola mierne nižšia.
%\todo

%\begin{table}[h]
%\catcode`\-=12 %kvoli babelu a pomlcke
%\centering
%\begin{tabular}{|l|c|c|c|c|c|}
%\cline{2-5}
%\multicolumn{1}{l}{} & \multicolumn{2}{|c|}{\textbf{Testovacia množina}} & \multicolumn{2}{c|}{\textbf{Trénovacia množina}} & \multicolumn{1}{l}{}\\ 
%\hline
%\textbf{Typ dát} & \textbf{úspešnosť} & \textbf{chyba} & \textbf{úspešnosť} & \textbf{chyba} & \textbf{čas} \\ \hline
%\textbf{Rozdielový obr.} & 83,33\% & 0,0745 & & & \\ \hline
%\textbf{Pôvodný obr.} & 68,52\% & 0,1174& & &\\ \hline
%\textbf{Rozdielový -- FT} & 75,18\%& 0,0895& & &\\ \hline
%\textbf{Pôvodný -- FT} & 70.37\%& 0,1158& & &\\
%\hline
%\end{tabular}
%\caption{Porovnanie úspešnosti NS pri rôznych dátach}
%\label{tab:neuraldatacmp}
%\end{table}

%\todo